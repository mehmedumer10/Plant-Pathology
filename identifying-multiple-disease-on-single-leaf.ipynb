{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":25563,"databundleVersionId":2094376,"sourceType":"competition"},{"sourceId":6835343,"sourceType":"datasetVersion","datasetId":3929848}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing The Required Libraries**","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# import system libs\nimport os\nimport time\nimport shutil\nimport pathlib\nimport itertools\n\n# import data handling tools\nimport cv2\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras import regularizers\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint ('modules loaded')\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/plant-pathology-2021-fgvc8'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T02:16:07.723853Z","iopub.execute_input":"2023-10-31T02:16:07.724153Z","iopub.status.idle":"2023-10-31T02:16:44.663107Z","shell.execute_reply.started":"2023-10-31T02:16:07.724130Z","shell.execute_reply":"2023-10-31T02:16:44.662156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Loading the Data**","metadata":{}},{"cell_type":"code","source":"# Dataset Files Paths\ntrain_image_path = '../input/plant-pathology-2021-fgvc8/train_images'\ntest_image_path = '../input/plant-pathology-2021-fgvc8/test_images'\ntrain_df_path = '../input/plant-pathology-2021-fgvc8/train.csv'\ntest_df_path = '../input/plant-pathology-2021-fgvc8/sample_submission.csv'","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.664585Z","iopub.execute_input":"2023-10-31T02:16:44.665061Z","iopub.status.idle":"2023-10-31T02:16:44.668251Z","shell.execute_reply.started":"2023-10-31T02:16:44.665036Z","shell.execute_reply":"2023-10-31T02:16:44.667694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loading data from directory\ntrain = pd.read_csv(train_df_path)\ntest = pd.read_csv(test_df_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.668803Z","iopub.execute_input":"2023-10-31T02:16:44.669016Z","iopub.status.idle":"2023-10-31T02:16:44.736750Z","shell.execute_reply.started":"2023-10-31T02:16:44.668982Z","shell.execute_reply":"2023-10-31T02:16:44.736049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analyzing and Reading the Data**","metadata":{}},{"cell_type":"code","source":"train.head(50)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.737723Z","iopub.execute_input":"2023-10-31T02:16:44.737923Z","iopub.status.idle":"2023-10-31T02:16:44.757119Z","shell.execute_reply.started":"2023-10-31T02:16:44.737904Z","shell.execute_reply":"2023-10-31T02:16:44.756466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking at basic infos\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.760410Z","iopub.execute_input":"2023-10-31T02:16:44.760649Z","iopub.status.idle":"2023-10-31T02:16:44.781978Z","shell.execute_reply.started":"2023-10-31T02:16:44.760622Z","shell.execute_reply":"2023-10-31T02:16:44.781238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the number of images\nprint(\"Number of images:\",len(train))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.782832Z","iopub.execute_input":"2023-10-31T02:16:44.783066Z","iopub.status.idle":"2023-10-31T02:16:44.787382Z","shell.execute_reply.started":"2023-10-31T02:16:44.783046Z","shell.execute_reply":"2023-10-31T02:16:44.786576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.788462Z","iopub.execute_input":"2023-10-31T02:16:44.788932Z","iopub.status.idle":"2023-10-31T02:16:44.800537Z","shell.execute_reply.started":"2023-10-31T02:16:44.788905Z","shell.execute_reply":"2023-10-31T02:16:44.799656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualizing the Labels** ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Count the occurrences of each label in the dataset\nlabel_counts = train['labels'].value_counts().reset_index()\n\n# Rename the columns for clarity\nlabel_counts.columns = ['Label', 'Count']\n\n# Create a bar plot using Seaborn\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Count', y='Label', data=label_counts, palette=\"viridis\")\n\n# Set labels and title\nplt.xlabel('Count')\nplt.ylabel('Label')\nplt.title('Distribution of Dataset Labels')\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:44.801587Z","iopub.execute_input":"2023-10-31T02:16:44.802028Z","iopub.status.idle":"2023-10-31T02:16:45.132679Z","shell.execute_reply.started":"2023-10-31T02:16:44.801983Z","shell.execute_reply":"2023-10-31T02:16:45.131835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# preparing the path to images\ntrain[\"path\"] = \"../input/plant-pathology-2021-fgvc8/train_images/\" + train[\"image\"]\n\n# taking a sample of the dataset\ndata_sample = train.sample(25)\n\n# Showing image sample\nplt.figure(figsize=(14, 9))\nn = 1\nfor i in data_sample.index:\n    plt.subplot(5, 5, n)\n    \n    testImage = mpimg.imread(data_sample[\"path\"][i])  # Use mpimg to read the image\n\n    # displaying the image\n    plt.imshow(testImage)\n\n    plt.title(data_sample[\"labels\"][i])\n    plt.axis(\"off\")\n    n += 1\n_ = plt.suptitle(\"Images sample\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:16:45.133941Z","iopub.execute_input":"2023-10-31T02:16:45.134207Z","iopub.status.idle":"2023-10-31T02:17:17.466361Z","shell.execute_reply.started":"2023-10-31T02:16:45.134185Z","shell.execute_reply":"2023-10-31T02:17:17.465416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def batch_visualize_with_label(df,batch_size,path,label): \n    sample_df = train[train[\"labels\"]==label].sample(9)\n    image_names = sample_df[\"image\"].values\n    labels = sample_df[\"labels\"].values\n    plt.figure(figsize=(16, 12))\n    \n    for image_ind, (image_name, label) in enumerate(zip(image_names, labels)):\n        plt.subplot(3, 3, image_ind + 1)\n        image = cv2.imread(os.path.join(path, image_name))\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        plt.imshow(image)\n        plt.axis(\"off\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:17:17.467516Z","iopub.execute_input":"2023-10-31T02:17:17.467756Z","iopub.status.idle":"2023-10-31T02:17:17.473189Z","shell.execute_reply.started":"2023-10-31T02:17:17.467735Z","shell.execute_reply":"2023-10-31T02:17:17.472604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'healthy')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:17:17.473968Z","iopub.execute_input":"2023-10-31T02:17:17.474435Z","iopub.status.idle":"2023-10-31T02:17:29.695547Z","shell.execute_reply.started":"2023-10-31T02:17:17.474415Z","shell.execute_reply":"2023-10-31T02:17:29.694019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'scab')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:17:29.696653Z","iopub.execute_input":"2023-10-31T02:17:29.696910Z","iopub.status.idle":"2023-10-31T02:17:41.650507Z","shell.execute_reply.started":"2023-10-31T02:17:29.696888Z","shell.execute_reply":"2023-10-31T02:17:41.649779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'frog_eye_leaf_spot')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:17:41.651480Z","iopub.execute_input":"2023-10-31T02:17:41.652079Z","iopub.status.idle":"2023-10-31T02:17:53.512017Z","shell.execute_reply.started":"2023-10-31T02:17:41.652054Z","shell.execute_reply":"2023-10-31T02:17:53.511360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'rust')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:17:53.515506Z","iopub.execute_input":"2023-10-31T02:17:53.515875Z","iopub.status.idle":"2023-10-31T02:18:06.221430Z","shell.execute_reply.started":"2023-10-31T02:17:53.515854Z","shell.execute_reply":"2023-10-31T02:18:06.220780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'complex')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:06.222348Z","iopub.execute_input":"2023-10-31T02:18:06.222687Z","iopub.status.idle":"2023-10-31T02:18:18.096509Z","shell.execute_reply.started":"2023-10-31T02:18:06.222666Z","shell.execute_reply":"2023-10-31T02:18:18.095753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_visualize_with_label(train,9,train_image_path,'powdery_mildew')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:18.097330Z","iopub.execute_input":"2023-10-31T02:18:18.097820Z","iopub.status.idle":"2023-10-31T02:18:29.934068Z","shell.execute_reply.started":"2023-10-31T02:18:18.097797Z","shell.execute_reply":"2023-10-31T02:18:29.933243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:29.935202Z","iopub.execute_input":"2023-10-31T02:18:29.935447Z","iopub.status.idle":"2023-10-31T02:18:29.942872Z","shell.execute_reply.started":"2023-10-31T02:18:29.935425Z","shell.execute_reply":"2023-10-31T02:18:29.942098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:29.944122Z","iopub.execute_input":"2023-10-31T02:18:29.944505Z","iopub.status.idle":"2023-10-31T02:18:29.957154Z","shell.execute_reply.started":"2023-10-31T02:18:29.944483Z","shell.execute_reply":"2023-10-31T02:18:29.956348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the number of images\nprint(\"Number of images:\",len(test))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:29.958466Z","iopub.execute_input":"2023-10-31T02:18:29.959037Z","iopub.status.idle":"2023-10-31T02:18:29.967607Z","shell.execute_reply.started":"2023-10-31T02:18:29.958992Z","shell.execute_reply":"2023-10-31T02:18:29.966975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.labels.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:29.968536Z","iopub.execute_input":"2023-10-31T02:18:29.969403Z","iopub.status.idle":"2023-10-31T02:18:29.978196Z","shell.execute_reply.started":"2023-10-31T02:18:29.969375Z","shell.execute_reply":"2023-10-31T02:18:29.977553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Piechart of labels**","metadata":{}},{"cell_type":"code","source":"# Count the occurrences of each label in the dataset\nlabel_counts = train['labels'].value_counts()\n\n# Get the label names and their corresponding counts\nlabel_list = label_counts.index\nlabel_counts = label_counts.values\n\n# Create a pie chart\nplt.figure(figsize=(10, 10))\nplt.pie(label_counts, labels=label_list, autopct='%1.1f%%')\nplt.title('Distribution of Dataset Labels')\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\n# Display the pie chart\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:29.979078Z","iopub.execute_input":"2023-10-31T02:18:29.979827Z","iopub.status.idle":"2023-10-31T02:18:30.225018Z","shell.execute_reply.started":"2023-10-31T02:18:29.979806Z","shell.execute_reply":"2023-10-31T02:18:30.224207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN Model with Data Augmentation Technique**","metadata":{}},{"cell_type":"code","source":"HEIGHT = 128\nWIDTH=128\nSEED = 45\nBATCH_SIZE= 64\n\ntrain_datagen = ImageDataGenerator(rescale = 1/255.,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split = 0.2,\n    zoom_range = 0.2,\n    shear_range = 0.2,\n    vertical_flip = False)\n\ntrain_dataset = train_datagen.flow_from_dataframe(\n    train,\n    directory = train_image_path,\n    x_col = \"image\",\n    y_col = \"labels\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode='categorical',\n    batch_size = BATCH_SIZE,\n    subset = \"training\",\n    shuffle = True,\n    seed = SEED,\n    validate_filenames = False\n)\n\nvalidation_dataset = train_datagen.flow_from_dataframe(\n    train,\n    directory = train_image_path,\n    x_col = \"image\",\n    y_col = \"labels\",\n    target_size = (HEIGHT,WIDTH),\n    class_mode='categorical',\n    batch_size = BATCH_SIZE,\n    subset = \"validation\",\n    shuffle = True,\n    seed = SEED,\n    validate_filenames = False\n)\n\ntest_datagen = ImageDataGenerator(\n    rescale = 1./255\n)\nINPUT_SIZE = (HEIGHT,WIDTH,3)\ntest_dataset=test_datagen.flow_from_dataframe(\n    test,\n    directory=test_image_path,\n    x_col='image',\n    y_col=None,\n    class_mode=None,\n    target_size=INPUT_SIZE[:2]\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:30.226135Z","iopub.execute_input":"2023-10-31T02:18:30.226441Z","iopub.status.idle":"2023-10-31T02:18:30.315447Z","shell.execute_reply.started":"2023-10-31T02:18:30.226412Z","shell.execute_reply":"2023-10-31T02:18:30.314698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',padding='same',input_shape=(HEIGHT,WIDTH,3)))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(64,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Conv2D(128,(3,3),activation='relu',padding='same'))\nmodel.add(MaxPooling2D(2,2))\nmodel.add(Flatten())\nmodel.add(Dense(12,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:30.316412Z","iopub.execute_input":"2023-10-31T02:18:30.316638Z","iopub.status.idle":"2023-10-31T02:18:30.489787Z","shell.execute_reply.started":"2023-10-31T02:18:30.316610Z","shell.execute_reply":"2023-10-31T02:18:30.488934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:30.490830Z","iopub.execute_input":"2023-10-31T02:18:30.491094Z","iopub.status.idle":"2023-10-31T02:18:30.529034Z","shell.execute_reply.started":"2023-10-31T02:18:30.491072Z","shell.execute_reply":"2023-10-31T02:18:30.528278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = \"training_1/cp.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create a callback that saves the model's weights\ncp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:30.530209Z","iopub.execute_input":"2023-10-31T02:18:30.530432Z","iopub.status.idle":"2023-10-31T02:18:30.534427Z","shell.execute_reply.started":"2023-10-31T02:18:30.530411Z","shell.execute_reply":"2023-10-31T02:18:30.533664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_model=model.fit_generator(train_dataset,\n                                  validation_data=validation_dataset,\n                                  epochs=20,\n                                  verbose=1,\n                                  shuffle=True,\n                                  steps_per_epoch=train_dataset.samples//128,\n                                  validation_steps=validation_dataset.samples//128,\n                                  callbacks=[cp_callback]\n                                 )","metadata":{"execution":{"iopub.status.busy":"2023-10-31T02:18:30.535680Z","iopub.execute_input":"2023-10-31T02:18:30.535968Z","iopub.status.idle":"2023-10-31T03:41:55.339657Z","shell.execute_reply.started":"2023-10-31T02:18:30.535940Z","shell.execute_reply":"2023-10-31T03:41:55.335197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = cnn_model.history\n\nplt.figure()\nplt.plot(model_history['accuracy'])\nplt.plot(model_history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.savefig('accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:41:55.349104Z","iopub.execute_input":"2023-10-31T03:41:55.354912Z","iopub.status.idle":"2023-10-31T03:41:55.814635Z","shell.execute_reply.started":"2023-10-31T03:41:55.354858Z","shell.execute_reply":"2023-10-31T03:41:55.813574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report of CNN Model Using Data Augmuntation Technique**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Make predictions on the validation dataset\nvalidation_predictions = model.predict(validation_dataset)\n\n# Convert one-hot encoded labels back to class labels\npredicted_labels = [np.argmax(pred) for pred in validation_predictions]\ntrue_labels = [np.argmax(label) for label in validation_dataset.labels]\n\n# Get the class labels\nclass_labels = list(validation_dataset.class_indices.keys())\n\n# Generate a classification report\nreport = classification_report(true_labels, predicted_labels, labels=class_labels)\n\n# Print the classification report\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:41:55.816213Z","iopub.execute_input":"2023-10-31T03:41:55.816445Z","iopub.status.idle":"2023-10-31T03:45:20.887920Z","shell.execute_reply.started":"2023-10-31T03:41:55.816425Z","shell.execute_reply":"2023-10-31T03:45:20.887024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN Model without Using Data Augmentation Technique**","metadata":{}},{"cell_type":"code","source":"# Define the batch size and input size\nBATCH_SIZE = 64\nHEIGHT = 128\nWIDTH = 128\nSEED = 45\n# Create a data generator without data augmentation\ndatagen = ImageDataGenerator(rescale=1/255.)\n\ntrain_dataset = datagen.flow_from_dataframe(\n    train,\n    directory=train_image_path,\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(HEIGHT, WIDTH),\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=SEED,\n    validate_filenames=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:45:20.889328Z","iopub.execute_input":"2023-10-31T03:45:20.889573Z","iopub.status.idle":"2023-10-31T03:45:21.002779Z","shell.execute_reply.started":"2023-10-31T03:45:20.889551Z","shell.execute_reply":"2023-10-31T03:45:21.001914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a model without data augmentation\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(HEIGHT, WIDTH, 3)))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Flatten())\nmodel.add(Dense(12, activation='softmax'))\n\n# Compile the model\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:45:21.003833Z","iopub.execute_input":"2023-10-31T03:45:21.004105Z","iopub.status.idle":"2023-10-31T03:45:21.125207Z","shell.execute_reply.started":"2023-10-31T03:45:21.004082Z","shell.execute_reply":"2023-10-31T03:45:21.124284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model without data augmentation\ncnn_model_without_data_augmentation = model.fit_generator(\n    train_dataset,\n    validation_data=validation_dataset,\n    epochs=10,\n    verbose=1,\n    shuffle=True,\n    steps_per_epoch=train_dataset.samples // 128,\n    validation_steps=validation_dataset.samples // 128\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T03:45:21.126257Z","iopub.execute_input":"2023-10-31T03:45:21.126475Z","iopub.status.idle":"2023-10-31T05:18:57.117888Z","shell.execute_reply.started":"2023-10-31T03:45:21.126455Z","shell.execute_reply":"2023-10-31T05:18:57.111299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = cnn_model_without_data_augmentation.history\n\nplt.figure()\nplt.plot(model_history['accuracy'])\nplt.plot(model_history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'])\nplt.savefig('accuracy')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:18:57.126420Z","iopub.execute_input":"2023-10-31T05:18:57.127518Z","iopub.status.idle":"2023-10-31T05:18:57.622012Z","shell.execute_reply.started":"2023-10-31T05:18:57.127479Z","shell.execute_reply":"2023-10-31T05:18:57.621144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Classification Report of CNN Model without Using Data Augmuntation Technique**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\n# Evaluate the model without data augmentation\ny_pred_without_data_augmentation = model.predict(train_dataset)\ny_true = train_dataset.classes\n\n# Convert one-hot encoded predictions to class labels\ny_pred_labels_without_data_augmentation = np.argmax(y_pred_without_data_augmentation, axis=1)\n\n# Generate classification report and confusion matrix for the model without data augmentation\nclassification_rep_without_data_augmentation = classification_report(y_true, y_pred_labels_without_data_augmentation, target_names=label_list)\nconfusion_matrix_without_data_augmentation = confusion_matrix(y_true, y_pred_labels_without_data_augmentation)\n\n# Evaluate the model with data augmentation\ny_pred = model.predict(validation_dataset)\n\n# Convert one-hot encoded predictions to class labels\ny_pred_labels = np.argmax(y_pred, axis=1)\n\n# Generate classification report and confusion matrix for the model with data augmentation\nclassification_rep = classification_report(validation_dataset.classes, y_pred_labels, target_names=label_list)\nconfusion_matrix_with_data_augmentation = confusion_matrix(validation_dataset.classes, y_pred_labels)\n\nprint(\"Classification Report for Model without Data Augmentation:\")\nprint(classification_rep_without_data_augmentation)\nprint(\"\\nConfusion Matrix for Model without Data Augmentation:\")\nprint(confusion_matrix_without_data_augmentation)\n\nprint(\"\\nClassification Report for Model with Data Augmentation:\")\nprint(classification_rep)\nprint(\"\\nConfusion Matrix for Model with Data Augmentation:\")\nprint(confusion_matrix_with_data_augmentation)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:18:57.623263Z","iopub.execute_input":"2023-10-31T05:18:57.623506Z","iopub.status.idle":"2023-10-31T05:35:31.553384Z","shell.execute_reply.started":"2023-10-31T05:18:57.623485Z","shell.execute_reply":"2023-10-31T05:35:31.552346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****InceptionResNetV2 Model And Comparison with other cnn methods****","metadata":{}},{"cell_type":"code","source":"# Load and preprocess the training dataset with one-hot encoded labels\ntrain_dataset = train_datagen.flow_from_dataframe(\n    train,\n    directory=train_image_path,\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(HEIGHT, WIDTH),\n    class_mode='categorical',  # This automatically one-hot encodes the labels\n    batch_size=BATCH_SIZE,\n    subset=\"training\",\n    shuffle=True,\n    seed=SEED,\n    validate_filenames=False\n)\n\n# Load and preprocess the validation dataset with one-hot encoded labels\nvalidation_dataset = train_datagen.flow_from_dataframe(\n    train,\n    directory=train_image_path,\n    x_col=\"image\",\n    y_col=\"labels\",\n    target_size=(HEIGHT, WIDTH),\n    class_mode='categorical',  # This automatically one-hot encodes the labels\n    batch_size=BATCH_SIZE,\n    subset=\"validation\",\n    shuffle=True,\n    seed=SEED,\n    validate_filenames=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T05:35:31.555488Z","iopub.execute_input":"2023-10-31T05:35:31.556765Z","iopub.status.idle":"2023-10-31T05:35:31.693554Z","shell.execute_reply.started":"2023-10-31T05:35:31.556731Z","shell.execute_reply":"2023-10-31T05:35:31.692636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import InceptionResNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Flatten, Dense\n\n# Define the number of classes in your dataset\nNUM_CLASSES = 12  # Replace with the actual number of classes\n\n# Define the InceptionResNetV2 model without weights\ninception_model = InceptionResNetV2(weights=None, include_top=False, input_shape=(HEIGHT, WIDTH, 3))\n\n# Add custom output layers\nflatten_layer = Flatten()(inception_model.output)\noutput_layer = Dense(NUM_CLASSES, activation='softmax')(flatten_layer)\n\n# Create a new model with custom output\ncustom_inception_model = Model(inputs=inception_model.input, outputs=output_layer)\n\n# Compile the model with appropriate loss and metrics\ncustom_inception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print a summary of the model to verify the architectured\ncustom_inception_model.summary()\n\n# Train the custom InceptionResNetV2 model\ncustom_inception_model.fit(train_dataset, epochs=5, validation_data=validation_dataset)\n","metadata":{},"execution_count":null,"outputs":[]}]}